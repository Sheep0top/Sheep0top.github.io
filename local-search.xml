<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【炼丹玩具】AI绘图LoKR训练角色概念的尝试</title>
    <link href="/2025/SDXL-LoKr/"/>
    <url>/2025/SDXL-LoKr/</url>
    
    <content type="html"><![CDATA[<h2 id="1-什么是LoKr"><a href="#1-什么是LoKr" class="headerlink" title="1.什么是LoKr"></a>1.什么是LoKr</h2><p>LoKr是微调技术的一种，属于Lycoris，其效果和应用场景类似于LoRA。</p><p>模型的训练实际上是模型参数的改变，利用梯度下降来计算模型参数的变化量$\Delta W$，最后用$W_{new} &#x3D; \Delta W + W_{before}$. </p><p><strong>LoRA</strong> (Low Rank Adaption，低秩微调)大概思想就是，如果我能用一个更好训练的低秩矩阵来替代$\Delta W$，就能实现更好的微调。</p><div align="center" style="margin: 20px 0;">  <!-- 图片 -->  <div style="text-align: center; padding: 10px 12px;">    <img src="https://img.cdn1.vip/i/68d39ef758af2_1758699255.webp"          style="max-width: 600px; width: 40%; height: auto; border-radius: 8px;" />  </div>  <!-- 图注 -->  <div style="color: #666; font-size: 0.9em; font-family: 'Helvetica', 'Arial', sans-serif; margin-top: 8px; text-align: center;">图1 LoRA原理图  </div></div><p>如上图所示，实际上LoRA的$\Delta W$用了BA两个矩阵的乘积来表示。</p><p>而LoKr的思想与之类似，两者的具体思想与理论证明本人仍未具体推理学习过，理论上两者都适用于模型的微调(常用于SD绘图，也可用于LLM)，具备参数量小的特点。相较于LoRA，LoKr更容易过拟合。</p><h2 id="2-实操训练LoKr"><a href="#2-实操训练LoKr" class="headerlink" title="2.实操训练LoKr"></a>2.实操训练LoKr</h2><p>在Windows环境下，使用秋叶训练器进行训练。<a href="https://gitee.com/Akegarasu/lora-scripts.git">https://gitee.com/Akegarasu/lora-scripts.git</a></p><p>选用底座模型为SDXL私模，数据集来源为互联网，打算训练mortis和muzimi，mortis大概30多张，muzimi大概20多张，每个epoch每张照片训练10次，训练20个epoch，batch&#x3D;3</p><p>直接总结失败经验：</p><h3 id="（1）参数设置错误"><a href="#（1）参数设置错误" class="headerlink" title="（1）参数设置错误"></a>（1）参数设置错误</h3><p>错误地把 <strong>factor</strong> 设置为默认的-1，导致lokr模型参数过小。</p><p>该参数越大训练出的模型越小，实测factor取3时，训练出的模型大小约为1.5GB。</p><h3 id="（2）打标问题"><a href="#（2）打标问题" class="headerlink" title="（2）打标问题"></a>（2）打标问题</h3><p>本次训练目标是训练两个角色概念，即用户在正面提示词处输入 mortis 或者 muzimi，即可保证生成对应的角色图像。但在打标过程中，直接用 JoyCaption2 的输出作为打标的文本。其中包含大量对待训练对象的<strong>详细外貌描写语句</strong>，使得最终训练出的模型无法正确理解两个触发词mortis&#x2F;muzimi的包含的图像信息。</p><p>我采取人工重新打标的方式后，一张张看照片，再根据joycaption的输出自行删减修改每一个打标文件。</p><h3 id="（3）图像预处理问题"><a href="#（3）图像预处理问题" class="headerlink" title="（3）图像预处理问题"></a>（3）图像预处理问题</h3><p>收集到的初始数据集存在分辨率大小不一，比例不统一等一系列问题。训练过程中训练器能自动识别<strong>不同比例</strong>的图片并将其进行缩放到不同的bucket之中，因此只要保证训练集足够大，图片的比例种类不要太多即可，真正造成困扰的是<strong>分辨率</strong>问题。SDXL训练目标为1024*1024像素，如果输入1920*1080像素的照片，则会将其进行等比例缩放，使得<strong>长边</strong>恰好为1024像素，即1920*1080–&gt;1024*576，而训练器自带的像素缩放工具会导致图像过于模糊。</p><p>我采取的解决方式如下：将所有数据集图像从png–&gt;jpg，用python脚本缩放至长边1024，用SeedVR2放大至1024(此时<strong>短边</strong>为1024，但图片格式被转为了png)，再用python脚本缩放至<strong>长边</strong>1024，并将图像转为jpg。</p><p>经过以上操作的图片，可肉眼可见的发现图像质量有所上升，否则会导致模型学习到模糊的人像。</p><h3 id="（4）未知问题（未解决）"><a href="#（4）未知问题（未解决）" class="headerlink" title="（4）未知问题（未解决）"></a>（4）未知问题（未解决）</h3><p>疑似是参数设计错误，我在训练的时候采用的图像预览（即每训练到一定程度，会用指定提示词生成图像），预览出的图像均正常，但实际拿到LoKr模型后，发现只要加载该模型，最终输出的图像都会变成灰蒙蒙的，偶尔能隐约看到一点轮廓。再重新配置完参数，删除数据集的.npz文件，再训练出的模型就没问题。</p><h2 id="3-效果与仍未解决的问题"><a href="#3-效果与仍未解决的问题" class="headerlink" title="3.效果与仍未解决的问题"></a>3.效果与仍未解决的问题</h2><h3 id="（1）只能稳定触发单个触发词"><a href="#（1）只能稳定触发单个触发词" class="headerlink" title="（1）只能稳定触发单个触发词"></a>（1）只能稳定触发单个触发词</h3><p>能识别到单人触发词，例如单独的 muzimi 或者单独的 mortis 都能正常输出比较正确的图像，但遇到”mortis and muzimi”双人的照片则表现效果不佳，两人的外貌特征输出有误，往往以第一个角色为主，且或许由于数据集不平等的原因，影响力mortis&gt;muzimi。</p><div align="center" style="margin: 20px 0;">  <div style="display: flex; justify-content: center; gap: 20px; align-items: flex-start; margin-bottom: 10px;">    <img src="https://img.cdn1.vip/i/68d3a1760e5b0_1758699894.webp"           style="max-width: 300px; height: auto; border-radius: 8px;" />    <img src="https://img.cdn1.vip/i/68d3a28ca7421_1758700172.webp"           style="max-width: 300px; height: auto; border-radius: 8px;" />  </div>  <div style="color: #666; font-size: 0.9em; font-family: 'Helvetica', 'Arial', sans-serif; margin-top: 8px;">    Prompt:two girls, mortis and muzimi/muzimi and mortis, they look at the camera with guitar in their hand.  </div></div><h3 id="（2）打标不完善"><a href="#（2）打标不完善" class="headerlink" title="（2）打标不完善"></a>（2）打标不完善</h3><p>例如mortis的数据集内包含较多的手机挡脸自拍照，打标过程中并未能很好体现<strong>手机遮脸</strong>这一特征，导致直接用mortis出图可能会出现类似的图。</p><p>例如部分打标文本中存在”serious expression”等包含神态的语句，我在人工打标的过程中没有删除，导致模型可能学习到了奇怪的面部，在生图过程如果不加以面部描述可能导致面部扭曲。</p><p>打标过程使用记事本+图片预览，效率过低。</p><h3 id="（3）细节学习有误"><a href="#（3）细节学习有误" class="headerlink" title="（3）细节学习有误"></a>（3）细节学习有误</h3><p>经典的手指学习不完备，可能输出“多手的怪物”。guitar疑似出现过拟合，生成的guitar可能奇奇怪怪不完备。muzimi可能会“长出帽子”。</p><div align="center" style="margin: 20px 0;">  <div style="display: flex; justify-content: center; gap: 20px; align-items: flex-start; margin-bottom: 10px;">    <img src="https://img.cdn1.vip/i/68d391f83ac45_1758695928.webp"           style="max-width: 300px; height: auto; border-radius: 8px;" />    <img src="https://img.cdn1.vip/i/68d3941843779_1758696472.webp"           style="max-width: 300px; height: auto; border-radius: 8px;" />  </div>Prompt:mortis/muzimi, full body, looking at the camera with guitar in her hand  <div style="color: #666; font-size: 0.9em; font-family: 'Helvetica', 'Arial', sans-serif; margin-top: 8px;">]]></content>
    
    
    
    <tags>
      
      <tag>SDXL-LoKr训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
